{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras_image_classification.py","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOjFmf5bG/7/Ogp3sbssgf5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFx88vctjdZ3","executionInfo":{"status":"ok","timestamp":1627300429419,"user_tz":-540,"elapsed":380,"user":{"displayName":"서경원","photoUrl":"","userId":"14902990287226846786"}},"outputId":"cfe10553-a1e1-4ff3-9e3d-9c077765fc22"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdUhVhDik5t7","executionInfo":{"status":"ok","timestamp":1627300431033,"user_tz":-540,"elapsed":15,"user":{"displayName":"서경원","photoUrl":"","userId":"14902990287226846786"}},"outputId":"d24868e8-373c-4cb0-8bb8-fd2e0c812eb7"},"source":["cd /content/drive/MyDrive/image_classification/Keras_CNN_image_classification"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/image_classification/Keras_CNN_image_classification\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1TUTCcEpwiR","executionInfo":{"status":"ok","timestamp":1627301117843,"user_tz":-540,"elapsed":425,"user":{"displayName":"서경원","photoUrl":"","userId":"14902990287226846786"}},"outputId":"cd5cf3f0-c7a2-4d97-fbe9-957a2884c017"},"source":["## read_img.py\n","import os\n","import cv2\n","#根据输入的文件夹绝对路径，将该文件夹下的所有指定suffix的文件读取存入一个list,该list的第一个元素是该文件夹的名字\n","# 폴더의 입력된 절대 경로에 따라 폴더에 지정된 모든 접미사 파일을 읽고 목록에 저장합니다. 목록의 첫 번째 요소는 폴더 이름입니다.\n","def readAllImg(path,*suffix):\n","    try:\n","\n","        s = os.listdir(path)\n","        resultArray = []\n","        fileName = os.path.basename(path)\n","        resultArray.append(fileName)\n","\n","        for i in s:\n","            if endwith(i, suffix):\n","                document = os.path.join(path, i)\n","                img = cv2.imread(document)\n","                resultArray.append(img)\n","\n","\n","    except IOError:\n","        print (\"Error\")\n","\n","    else:\n","        print (\"读取成功\")\n","        return resultArray\n","\n","#输入一个字符串一个标签，对这个字符串的后续和标签进行匹配\n","def endwith(s,*endstring):\n","   resultArray = map(s.endswith,endstring)\n","   if True in resultArray:\n","       return True\n","   else:\n","       return False\n","\n","if __name__ == '__main__':\n","\n","  result = readAllImg(\"/content/drive/MyDrive/image_classification/Keras_CNN_image_classification/위성사진\",'.png')\n","  print (result[0])\n","  # cv2.namedWindow(\"Image\")\n","  # cv2.imshow(\"Image\", result[1])\n","  # cv2.waitKey(0)\n","  # cv2.destroyAllWindows()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["读取成功\n","위성사진\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-EB_gpZhqZ85"},"source":["## read_data\n","# coding= utf-8\n","import os\n","import cv2\n","import numpy as np\n","\n","# from read_img import endwith\n","\n","#输入一个文件路径，对其下的每个文件夹下的图片读取，并对每个文件夹给一个不同的Label\n","#返回一个img的list,返回一个对应label的list,返回一下有几个文件夹（有几种label)\n","\n","def read_file(path):\n","    img_list = []\n","    label_list = []\n","    dir_counter = 0\n","\n","\n","    #对路径下的所有子文件夹中的所有jpg文件进行读取并存入到一个list中\n","    for child_dir in os.listdir(path):\n","        child_path = os.path.join(path, child_dir)\n","         \n","        for dir_image in os.listdir(child_path):\n","            print(child_path)\n","            if endwith(dir_image,'jpg'):\n","                img = cv2.imread(os.path.join(child_path, dir_image))\n","                img =cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","                img_list.append(img)\n","                label_list.append(dir_counter)\n","\n","        dir_counter += 1\n","\n","    # 返回的img_list转成了 np.array的格式\n","    img_list = np.array(img_list)\n","\n","    return img_list,label_list,dir_counter\n","\n","#读取训练数据集的文件夹，把他们的名字返回给一个list\n","def read_name_list(path):\n","    name_list = []\n","    for child_dir in os.listdir(path):\n","        name_list.append(child_dir)\n","    return name_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VyVj-3kXqHl_"},"source":["## dataSet.py\n","# -*- coding: utf-8 -*-\n","\n","# from read_data import read_file\n","#from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import train_test_split\n","# cross_validation to model_selection\n","from keras.utils import np_utils\n","import random\n","\n","#建立一个用于存储和格式化读取训练数据的类\n","class DataSet(object):\n","    def __init__(self,path):\n","        self.num_classes = None\n","        self.X_train = None\n","        self.X_test = None\n","        self.Y_train = None\n","        self.Y_test = None\n","        self.extract_data(path)\n","        #在这个类初始化的过程中读取path下的训练数据\n","\n","    def extract_data(self,path):\n","        #根据指定路径读取出图片、标签和类别数\n","        imgs,labels,counter = read_file(path)\n","  \n","        print(\"输出标记\")\n","        print(labels)\n","\n","        #将数据集打乱随机分组    \n","        \n","        \n","        X_train,X_test,y_train,y_test = train_test_split(imgs,labels,test_size=0.4,random_state=random.randint(0, 100))\n","        print(\"输出训练标记和训练集长度\")\n","        print(y_train)\n","        print(len(X_train))\n","        print(X_train[1])\n","        print(\"测试长度和测试集标记\")\n","        print(len(X_test))\n","        print(y_test)\n","        print(\"输出和\")\n","        print(counter)\n","\n","        #重新格式化和标准化\n","        # 本案例是基于thano的，如果基于tensorflow的backend需要进行修改\n","        X_train = X_train.reshape(X_train.shape[0], 174, 212, 1)\n","        X_test = X_test.reshape(X_test.shape[0], 174, 212,1)\n","        \n","        \n","        X_train = X_train.astype('float32')/255\n","        X_test = X_test.astype('float32')/255\n","        print(X_train[1])\n","\n","        #将labels转成 binary class matrices\n","        Y_train = np_utils.to_categorical(y_train, num_classes=counter)\n","        Y_test = np_utils.to_categorical(y_test, num_classes=counter)\n","        \n","        print(Y_train)\n","        #将格式化后的数据赋值给类的属性上\n","        self.X_train = X_train\n","        self.X_test = X_test\n","        self.Y_train = Y_train\n","        self.Y_test = Y_test\n","        self.num_classes = counter\n","\n","    def check(self):\n","        print('num of dim:', self.X_test.ndim)\n","        print('shape:', self.X_test.shape)\n","        print('size:', self.X_test.size)\n","\n","        print('num of dim:', self.X_train.ndim)\n","        print('shape:', self.X_train.shape)\n","        print('size:', self.X_train.size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfH8qlnGjLpO","colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"status":"error","timestamp":1627301605189,"user_tz":-540,"elapsed":549,"user":{"displayName":"서경원","photoUrl":"","userId":"14902990287226846786"}},"outputId":"1ed1afaf-5886-4810-ac0b-881c8e635f27"},"source":["## train_model.py\n","# coding= utf-8\n","# from dataSet import DataSet\n","from keras.models import Sequential,load_model\n","from keras.layers import Dense,Activation,Convolution2D,MaxPooling2D,Flatten,Dropout,BatchNormalization\n","import numpy as np\n","from keras.callbacks import TensorBoard\n","# from keras.utils import plot_model\n","from keras.utils.vis_utils import plot_model\n","#建立一个基于CNN的识别模型\n","class Model(object):\n","    FILE_PATH = \"G:/desktop/myProject/model.h5\"   #模型进行存储和读取的地方\n","    \n","\n","    def __init__(self):\n","        self.model = None\n","\n","    #读取实例化后的DataSet类作为进行训练的数据源\n","    def read_trainData(self,dataset):\n","        self.dataset = dataset\n","\n","    #建立一个CNN模型，一层卷积、一层池化、一层卷积、一层池化、抹平之后进行全链接、最后进行分类      其中flatten是将多维输入一维化的函数 dense是全连接层\n","    def build_model(self):\n","        self.model = Sequential()\n","        self.model.add(\n","            Convolution2D(\n","                          \n","                filters=32,\n","                kernel_size=(5, 5),\n","                padding='same',\n","                dim_ordering='tf',\n","                input_shape=self.dataset.X_train.shape[1:], \n","               \n","            )\n","        )\n","        self.model.add( BatchNormalization())\n","\n","        self.model.add(Activation('relu'))\n","        self.model.add(\n","            MaxPooling2D(\n","                pool_size=(2, 2),\n","                strides=(2, 2), \n","                padding='same'\n","            )\n","        )\n","        \n","\n","        self.model.add(Convolution2D(filters=64, kernel_size=(5, 5), padding='same'))\n","        self.model.add(BatchNormalization())\n","        self.model.add(Activation('relu'))\n","        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n","        self.model.add(Dropout(0.15))\n","        \n","        \n","        self.model.add(Convolution2D(filters=64, kernel_size=(5, 5), padding='same'))\n","        self.model.add(BatchNormalization())\n","        self.model.add(Activation('relu'))\n","        self.model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n","        self.model.add(Dropout(0.15))\n","        \n","\n","        self.model.add(Flatten())\n","        self.model.add(Dense(512))\n","        self.model.add(BatchNormalization())\n","        self.model.add(Activation('relu'))\n","        self.model.add(Dropout(0.5))\n","        \n","        self.model.add(Dense(128))\n","        self.model.add(BatchNormalization())\n","        self.model.add(Activation('relu'))\n","        self.model.add(Dropout(0.5))\n","        \n","        self.model.add(Dense(self.dataset.num_classes))\n","        self.model.add(BatchNormalization())\n","        self.model.add(Activation('softmax'))\n","        self.model.summary()\n","#         plot_model(model,to_file='G:/desktop/myProject/model.png')\n","        \n","    #进行模型训练的函数，具体的optimizer、loss可以进行不同选择\n","    def train_model(self):\n","        self.model.compile(\n","            optimizer='adadelta',  #有很多可选的optimizer，例如RMSprop,Adagrad，你也可以试试哪个好，我个人感觉差异不大   adadelta\n","            loss='squared_hinge',  #你可以选用 categorical_crossentropy  squared_hinge作为loss看看哪个好\n","            metrics=['accuracy'])\n","\n","        #epochs、batch_size为可调的参数，epochs为训练多少轮、batch_size为每次训练多少个样本\n","        self.model.fit(self.dataset.X_train,self.dataset.Y_train,epochs=12,batch_size=20,callbacks=[TensorBoard(log_dir='G:/desktop/myProject/tmp/log')])\n","\n","    def evaluate_model(self):\n","        print('\\nTesting---------------')\n","        loss, accuracy = self.model.evaluate(self.dataset.X_test, self.dataset.Y_test)\n","\n","        print('test loss;', loss)\n","        print('test accuracy:', accuracy)\n","\n","    def save(self, file_path=FILE_PATH):\n","        print('Model Saved.')\n","        self.model.save(file_path)\n","\n","    def load(self, file_path=FILE_PATH):\n","        print('Model Loaded.')\n","        self.model = load_model(file_path)\n","\n","    #需要确保输入的img得是灰化之后（channel =1 )且 大小为IMAGE_SIZE的人脸图片\n","    def predict(self,img):\n","        img = img.reshape((1,  174, 212,1))\n","        img = img.astype('float32')\n","        img = img/255.0\n","        result = self.model.predict_proba(img)  #测算一下该img属于某个label的概率\n","        max_index = np.argmax(result) #找出概率最高的\n","\n","        return max_index,result[0][max_index] #第一个参数为概率最高的label的index,第二个参数为对应概率\n","\n","\n","if __name__ == '__main__':\n","    datast = DataSet('/content/drive/MyDrive/image_classification/Keras_CNN_image_classification/위성사진')\n","    model = Model()\n","    model.read_trainData(datast)\n","    model.build_model()\n","    model.train_model()\n","    model.evaluate_model()\n","    model.save()\n","    #score=model.evaluate()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NotADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-42d3fa64ee86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mdatast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/image_classification/Keras_CNN_image_classification/위성사진'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_trainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-66f5661ead62>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#在这个类初始化的过程中读取path下的训练数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-66f5661ead62>\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#根据指定路径读取出图片、标签和类别数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"输出标记\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-ed63e6585a8e>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mchild_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdir_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mendwith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/image_classification/Keras_CNN_image_classification/위성사진/101 MN-96, Dellwood, MN 55110 미국.PNG'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"94bPJhjNuuKy","executionInfo":{"status":"ok","timestamp":1627301543750,"user_tz":-540,"elapsed":405,"user":{"displayName":"서경원","photoUrl":"","userId":"14902990287226846786"}},"outputId":"8382ac58-978c-4db6-b010-da9cf2770717"},"source":["## test_model.py\n","# coding= utf-8\n","from read_data import read_name_list,read_file\n","from train_model import Model\n","import cv2\n","import os \n","import numpy as np\n","from read_img import endwith\n","from dataSet import DataSet\n","from keras import backend as K\n","from keras.utils import np_utils\n","\n","\n","K.clear_session()\n","# def test_onePicture(path):\n","#     model= Model()\n","#     model.load()\n","#     img = cv2.imread(path)\n","#     picType,prob = model.predict(img)\n","#     if picType != -1:\n","#         name_list = read_name_list('F:\\myProject\\pictures\\dataset')\n","#         print(name_list)\n","#         print( name_list[picType],prob)\n","#     else:\n","#         print (\" Don't know this person\")\n","\n","# #读取文件夹下子文件夹中所有图片进行识别\n","# def test_onBatch(path):\n","#     model= Model()\n","#     model.load()\n","#     index = 0\n","#     img_list, label_list, counter = read_file(path)\n","#     for i in range(len(img_list)):\n","#         picType,prob = model.predict(img_list[i])\n","#         if picType==label_list[i] & picType != -1:\n","#             index += 1\n","#     #计算预测正确的概率\n","#     pro_predict=float(index)/len(img_list)\n","#     return pro_predict\n","\n","#读取文件夹下子文件夹中所有图片进行识别\n","def test_onBatch(path):\n","    model= Model()\n","    model.load()\n","    index = 0\n","    img_list, label_list, counter = read_file(path)\n","#     img_list = img_list.reshape(img_list.shape[0], 174, 212, 1)\n","#     print(img_list.shape[0:])\n","#     img_list = img_list.astype('float32')/255\n","#     Label_list = np_utils.to_categorical(label_list, num_classes=counter)\n","    for img in img_list:\n","        picType,prob = model.predict(img)\n","        if picType != -1:\n","            index += 1\n","            name_list = read_name_list('G:/desktop/myProject/pictures/test')\n","            print(name_list)\n","            print (name_list[picType])\n","        else:\n","            print (\" Don't know this person\")\n","  \n","    return index"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/image_classification/Keras_CNN_image_classification'"]},"metadata":{"tags":[]},"execution_count":38}]}]}